# A 'sparse array' wrapper

# distutils: language = c++

import numpy as np
cimport numpy as cnp
from numpy cimport (npy_intp, npy_bool, npy_byte, npy_ubyte, npy_short, npy_int,
                    npy_long, npy_longlong, npy_ushort, npy_uint, npy_ulong,
                    npy_ulonglong, npy_cdouble)
from numpy cimport (NPY_BYTE, NPY_SHORT, NPY_INT, NPY_LONG, NPY_LONGLONG,
                    NPY_UBYTE, NPY_USHORT, NPY_UINT, NPY_ULONG, NPY_ULONGLONG,
                    NPY_FLOAT, NPY_DOUBLE, NPY_CDOUBLE, NPY_INTP, NPY_BOOL)
from numpy cimport PyArray_SimpleNew, PyArray_DATA, PyArray_SIZE

from cpython cimport PyObject
from cpython.object cimport PyObject_IsTrue, PyObject_RichCompare
from cpython.complex cimport (PyComplex_Check, PyComplex_FromDoubles,
                              PyComplex_RealAsDouble, PyComplex_ImagAsDouble)
from libcpp.vector cimport vector

from sparr.fixed_cap cimport index_type, index_factory_t, FC_ELEMS
from sparr.views cimport (map_array_t, abstract_view_t, map_view_t, view_view_t,
                          todense, to_coo, inplace_binop, apply_binop, apply_mmul)
from sparr.slices cimport slice_t, slices_from_pyslices, slices_from_pyslices2

cdef extern from "complex_ops.h":
    cdef cppclass npy_cdouble_wrapper:
        double real
        double imag

# Elementary elementwise operations
cdef extern from "elementwise_ops.h" namespace "sparray":
    T add[T](T, T)
    T mul[T](T, T)
    T sub[T](T, T)

    npy_bool equal[S](S, S)
    npy_bool less_equal[S](S, S)
    npy_bool greater_equal[S](S, S)
    npy_bool not_equal[S](S, S)
    npy_bool less[S](S, S)
    npy_bool greater[S](S, S)


cdef extern from "util.h" namespace "sparray":
    int _is_tuple_of_integers(object obj, index_type& idx, int)
    object validate_index[T, I](index_type& idx,
                             const abstract_view_t[T, I] *m,
                             int is_shape_fixed)


{{py:
CTYPES_GEN = ['npy_byte', 'npy_short', 'npy_int', 'npy_long', 'npy_longlong',
              'npy_ubyte', 'npy_ushort', 'npy_uint', 'npy_ulong', 'npy_ulonglong',
              'float', 'double']
TNUMS_GEN = ['NPY_BYTE', 'NPY_SHORT', 'NPY_INT', 'NPY_LONG', 'NPY_LONGLONG',
             'NPY_UBYTE', 'NPY_USHORT', 'NPY_UINT', 'NPY_ULONG', 'NPY_ULONGLONG',
             'NPY_FLOAT', 'NPY_DOUBLE']
CONDS_GEN = ['if'] + ['elif']*(len(TNUMS_GEN) - 1)

# add types which need special casing (eg get/set)
CTYPES = CTYPES_GEN + ['npy_bool', 'npy_cdouble_wrapper']
TNUMS = TNUMS_GEN + ['NPY_BOOL', 'NPY_CDOUBLE']
CONDS = CONDS_GEN + ['elif', 'elif']
}}


# the main polymorphism kludge :-)
cdef union union_t:
{{for CT in CTYPES}}
    map_array_t[{{CT}}, npy_intp] *{{CT}}_ptr
{{endfor}}


cdef union view_union_t:
{{for ct in CTYPES}}
    abstract_view_t[{{ct}}, npy_intp] *{{ct}}_ptr
{{endfor}}


cdef class Holder:
    """Only holds the map_array_t member. No python exposure.
    """
    cdef union_t p
    cdef int typenum

    def __cinit__(self, int typenum, int nd):
        self.typenum = typenum

        # allocate memory on the correct type pointer
        {{for NUM, CT, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} self.typenum == {{NUM}}:
            self.p.{{CT}}_ptr = new map_array_t[{{CT}}, npy_intp](nd)
        {{endfor}}
        else:
            dtype = np.dtype(cnp.PyArray_TypeObjectFromType(self.typenum))
            raise TypeError("dtype %s  not supported." % dtype)

    def __dealloc__(self):
        {{for NUM, CT, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} self.typenum == {{NUM}}:
            del self.p.{{CT}}_ptr
        {{endfor}}
        # NB: this if-then-else is deliberately not closed off with an error.
        # The reason is that if a dtype lookup fails in __cinit__, it raises
        # a TypeError, and then __dealloc__ is called by Cython anyway.
        # The result is a spurious message from __dealloc__ saying that
        # the error was ignored.


cdef class View:
    """Only holds a view onto the map_array_t object (which is managed
       separately, via a Holder class.)
       No python exposure.
    """
    cdef view_union_t p
    cdef int typenum

    @staticmethod
    def from_data(int typenum, Holder holder not None):
        """Construct a view onto the data held by `holder`.

        Parameters
        ----------
        typenum : int
            numpy-style type number
        holder : Holder
            a Holder object, wrapping a map_array_t data

        Returns
        -------
        A View wrapper over a map_view_t object, viewing onto the data held
        by `holder`. This is an identical view, which views the full data.

        """
        self = View()
        self.typenum = typenum

        assert typenum == holder.typenum

        # allocate memory on the correct type pointer
        {{for num, ct, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} self.typenum == {{num}}:
            self.p.{{ct}}_ptr = new map_view_t[{{ct}}, npy_intp](holder.p.{{ct}}_ptr)
        {{endfor}}
        else:
            dtype = np.dtype(cnp.PyArray_TypeObjectFromType(self.typenum))
            raise TypeError("dtype %s  not supported." % dtype)
        return self

    @staticmethod
    def from_view(int typenum, View view not None, object pyslices):
        """Construct a composite view, wrapping a view_view_t object.

        Parameters
        ----------
        typenum : int
            numpy-style type number
        view : View
            a base view
        pyslices : tuple
            a tuple of slices

        Returns
        -------
        A View wrapper over a view_view_t object, viewing onto the same
        data as the `view`.
        This mimicks an indexing operation similar to a[::2][::2]

        """
        self = View()
        self.typenum = typenum
        assert typenum == view.typenum

        cdef vector[slice_t] sl, sl0
        {{for num, ct, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} {{num}} == typenum:
            sl0 = view.p.{{ct}}_ptr.get_slices()

            if sl0.empty():
                sl = slices_from_pyslices(<PyObject *>pyslices,
                                          view.p.{{ct}}_ptr.shape())
            else:
                sl = slices_from_pyslices2(sl0, <PyObject *>pyslices)
            self.p.{{ct}}_ptr = new view_view_t[{{ct}}, npy_intp](view.p.{{ct}}_ptr, sl)
        {{endfor}}
        else:
            dtype = np.dtype(cnp.PyArray_TypeObjectFromType(self.typenum))
            raise TypeError("dtype %s  not supported." % dtype)
        return self

    @staticmethod
    def from_view_and_data(int typenum, Holder holder not None, View view not None):
        """Construct a new view onto the `holder`'s data using `view`'s converter

        Parameters
        ----------
        typenum : int
            numpy-style type number
        holder : Holder
            the base data
        view : View
            a base view

        Returns
        -------
        A View wrapper over a view_view_t object, viewing into the `holder`'s data
        with the `view`'s converter.

        """
        self = View()
        self.typenum = typenum
        assert typenum == holder.typenum

        # figure out the view's typenum and extract the slice vector
        cdef vector[slice_t] sl
        {{for num, ct, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} {{num}} == view.typenum:
            sl = view.p.{{ct}}_ptr.get_slices()
        {{endfor}}

        # allocate the new view
        {{for num, ct, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} {{num}} == typenum:
            if sl.empty():
                self.p.{{ct}}_ptr = new map_view_t[{{ct}}, npy_intp](holder.p.{{ct}}_ptr)
            else:
                self.p.{{ct}}_ptr = new view_view_t[{{ct}}, npy_intp](holder.p.{{ct}}_ptr, sl)
        {{endfor}}
        else:
            dtype = np.dtype(cnp.PyArray_TypeObjectFromType(self.typenum))
            raise TypeError("dtype %s  not supported." % dtype)
        return self


    def __dealloc__(self):
        {{for num, ct, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} self.typenum == {{num}}:
            del self.p.{{ct}}_ptr
        {{endfor}}
        # NB: this if-then-else is deliberately not closed off with an error.
        # The reason is that if a dtype lookup fails in __cinit__, it raises
        # a TypeError, and then __dealloc__ is called by Cython anyway.
        # The result is a spurious message from __dealloc__ saying that
        # the error was ignored.


cdef class MapArray:
    """A DOK format sparse array.

    A two-dimensional sparse array, suitable for incremental construction.
    Inserting new elements is efficient.
    Semantics of this object should mostly mimic the numpy array.

    Parameters
    ----------
    shape: 2-element tuple of ints, optional
        The shape of the array. Default is zero.
    fill_value : scalar, optional
        The value assumed for the missing entries. Default is zero.
    dtype : optional
        Default is python's float. 

    Attributes
    ----------
    ndim
    shape
    dtype
    fill_value
    
    Methods
    -------
    astype
    copy
    count_nonzero
    todense
    from_dense
    to_coo
    from_coo

    Examples
    --------
    >>> from sp_map import MapArray as M
    >>> m = M()
    >>> m.shape
    (0, 0)

    Inserting new elements expands the array

    >>> m[1, 2] = -101
    >>> m.shape
    (2, 3)
    >>> m[0, 3] = 42
    >>> m.shape
    (2, 4)
    >>> m.todense()
    array([[   0.,    0.,    0.,   42.],
           [   0.,    0., -101.,    0.]])

    Arithmetic operations are elementwise

    >>> m2 = m * m + 1
    >>> m2.to_coo()
    (array([  1765.,  10202.]), (array([0, 1]), array([3, 2])))

    """
    cdef Holder holder
    cdef View view
    cdef MapArray _base
    cdef int typenum
    cdef int _is_shape_fixed
    cdef index_factory_t *index_factory

    __array_priority__ = 10.1     # equal to that of sparse matrices

    def __init__(self, shape=None, ndim=None, fill_value=None, dtype=None):
        pass

    def __cinit__(self, shape=None, ndim=None, fill_value=None, dtype=None, *args, **kwds):

        if dtype is None:
            if fill_value is None:
                dtype = np.dtype(float)
                fill_value = 0.0
            else:
                dtype = np.asarray(fill_value).dtype
        else:
            if fill_value is None:
                fill_value = 0

        # this seems to convert float etc to numpy dtypes
        dtype = np.dtype(dtype)
        self.typenum = dtype.num

        # shape/ndim: if none are given, default is ndim=2, shape=None
        if shape is None:
            self._is_shape_fixed = False
            if ndim is None:
                ndim = 2
            shape = (0,)*ndim
        else:
            self._is_shape_fixed = True
            if ndim is None:
                ndim = len(shape)
            else:
                if len(shape) != ndim:
                    raise ValueError("shape = %s and ndim= %s are ambiguous" %
                                     (shape, ndim))

        # have ndim and shape, validate
        if ndim != int(ndim):
            raise ValueError("ndim: Expected integer, got %s." % ndim)
        cdef int nd = ndim
        self.index_factory = new index_factory_t(nd)

        cdef index_type shp = self.index_factory.get_new()
        if not _is_tuple_of_integers(shape, shp, nd):
                raise TypeError("Shape %s not undestood." % str(shape))

        # allocate memory on the correct type pointer
        self.holder = Holder(self.typenum, nd)
        self.view = View.from_data(self.typenum, self.holder)
        self._base = None

        {{for NUM, CT, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} self.typenum == {{NUM}}:
            self.view.p.{{CT}}_ptr.set_shape(shp)
        {{endfor}}
        else:
            raise TypeError("dtype %s  not supported." % dtype)

        # handle fill_value
        self.fill_value = fill_value

    def __dealloc__(self):
        del self.index_factory

    #### Public interface accessors #####

    property dtype:
        def __get__(self):
            # per https://mail.scipy.org/pipermail/numpy-discussion/2013-October/068002.html
            return np.dtype(cnp.PyArray_TypeObjectFromType(self.typenum))

    property ndim:
        def __get__(self):
            cdef int nd
            {{for NUM, C, IF in zip(TNUMS, CTYPES, CONDS)}}
            {{IF}} self.typenum == {{NUM}}:
                nd = self.view.p.{{C}}_ptr.ndim()
                if nd != self.index_factory.ndim():
                    raise RuntimeError("Panic: self._ndim = %s != ptr.ndim = %s."
                                        % (self.index_factory.ndim(), nd))
                return nd
            {{endfor}}
            else:
                raise TypeError("ndim: dtype = %s unhandled." % self.dtype)

    property fill_value:
        def __get__(self):
            cdef npy_cdouble_wrapper z
            {{for NUM, C, IF in zip(TNUMS_GEN, CTYPES_GEN, CONDS_GEN)}}
            {{IF}} self.typenum == {{NUM}}:
                return self.view.p.{{C}}_ptr.fill_value()
            {{endfor}}
            elif self.typenum == NPY_BOOL:
                return self.view.p.npy_bool_ptr.fill_value() != 0
            elif self.typenum == NPY_CDOUBLE:
                z = self.view.p.npy_cdouble_wrapper_ptr.fill_value()
                return PyComplex_FromDoubles(z.real, z.imag)
            else:
                raise TypeError("fill_value: dtype = %s unhandled." % self.dtype)

        def __set__(self, value):
            cdef int ival
            cdef npy_cdouble_wrapper z
            {{for NUM, C, IF in zip(TNUMS_GEN, CTYPES_GEN, CONDS_GEN)}}
            {{IF}} self.typenum == {{NUM}}:
                self.view.p.{{C}}_ptr.set_fill_value(value)
            {{endfor}}
            elif self.typenum == NPY_BOOL:
                ival = PyObject_IsTrue(value)
                if ival == -1:
                    raise ValueError("Cannot interpet %s as a boolean" % value)
                self.view.p.npy_bool_ptr.set_fill_value(ival)
            elif self.typenum == NPY_CDOUBLE:
                ival = PyComplex_Check(value)
                if ival == -1:
                    raise ValueError("Cannot interpret %s as a complex number" % value)
                z.real = PyComplex_RealAsDouble(value)
                z.imag = PyComplex_ImagAsDouble(value)
                self.view.p.npy_cdouble_wrapper_ptr.set_fill_value(z)
            else:
                raise TypeError("fill_value: dtype = %s unhandled." % self.dtype)

    property base:
        def __get__(self):
            return self._base

    property shape:
        def __get__(self):
            cdef index_type sh = self.index_factory.get_new()
            cdef int nd = self.index_factory.ndim()
            {{for NUM, C, IF in zip(TNUMS, CTYPES, CONDS)}}
            {{IF}} self.typenum == {{NUM}}:
                sh = self.view.p.{{C}}_ptr.shape()
                return tuple(sh[i] for i in range(nd))
            {{endfor}}
            else:
                raise TypeError("shape: dtype = %s unhandled." % self.dtype)

    property is_shape_fixed:
        def __get__(self):
            return bool(self._is_shape_fixed)

        def __set__(self, value):
            self._is_shape_fixed = 1 if value else 0

    def count_nonzero(self):
        {{for NUM, C, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} self.typenum == {{NUM}}:
            return self.view.p.{{C}}_ptr.count_nonzero()
        {{endfor}}
        raise TypeError("count_nonzero: dtype = %s unhandled." % self.dtype)


    def copy(self, dtype=None):
        """Return a copy of self, optionally casting it to a specified dtype.

        Parameters
        ----------
        dtype : optional
            dtype to cast the copy to. Default is to preserve the dtype.

        See Also
        -----
        astype

        """
        if dtype is None:
            dtype = self.dtype
        newobj = MapArray(dtype=dtype, shape=self.shape)
        newobj.is_shape_fixed = False

        cdef int typenum_src = self.typenum
        cdef int typenum_dest = newobj.typenum
        {{for num, ct, IF in zip(TNUMS, CTYPES, CONDS)}}
        {{IF}} typenum_src == {{num}}:
            # found self.dtype, on to the dest dtype now
            {{for num1, ct1, IF1 in zip(TNUMS, CTYPES, CONDS)}}
            {{IF1}} typenum_dest == {{num1}}:
                newobj.holder.p.{{ct1}}_ptr.copy_from[{{ct}}, npy_intp](self.holder.p.{{ct}}_ptr)
                newobj.view = View.from_view_and_data({{num1}}, newobj.holder, self.view)
                return newobj
            {{endfor}}
        {{endfor}}
        raise TypeError("copy: never be here. dtype = " % self.dtype)

    def astype(self, dtype):
        """Return a copy of self, cast to a specified dtype.

        Parameters
        ----------
        dtype : dtype to cast the copy to.

        See Also
        -----
        copy

        """
        # Syntactic sugar: .copy() preserves dtype, .astype changes it.
        return self.copy(dtype)

    def __repr__(self):
        return ("<%dx%d sparse array of type '%s' with %d stored elements.>" %
               (self.shape + (self.dtype.type, self.count_nonzero())))

    def todense(self):
        """Return the dense array representation of self.

        Construct a numpy array of matching shape, dtype and data.

        """
        cdef int nd
        cdef cnp.ndarray a

        {{for num, ct in zip(TNUMS, CTYPES)}}
        if self.typenum == {{num}}:
            nd = <int>self.view.p.{{ct}}_ptr.ndim()
            a = PyArray_SimpleNew(nd,
                                  <npy_intp*>FC_ELEMS(self.view.p.{{ct}}_ptr.shape()),
                                  {{num}})
            todense[{{ct}}, npy_intp](self.view.p.{{ct}}_ptr, PyArray_DATA(a), PyArray_SIZE(a))
            return a
        {{endfor}}
        raise TypeError("todense: never be here. dtype = " % self.dtype)

    @classmethod
    def from_dense(cls, arr):
        """Construct from a dense array.
        """
        self = MapArray(dtype=arr.dtype, ndim=arr.ndim)
        for idx, val in np.ndenumerate(arr):
            self[idx] = val
        return self

    def to_coo(self):
        """Return COO style arrays for data, rows and columns.

        Returns
        -------
        data : ndarray
            Non-zero values.
        (row, col) : tuple of ndarrays
            Indices of nonzero elements, such that 
            ``self[row[k], col[k]] = data[k]``.

        Notes
        -----
        This function ignores the `fill_value`.

        """
        cdef int nd
        cdef npy_intp num_elem
        cdef npy_intp[1] sh
        cdef cnp.ndarray data, stacked_indices

        {{for num, ct in zip(TNUMS, CTYPES)}}
        if self.typenum == {{num}}:
            num_elem = <npy_intp>self.view.p.{{ct}}_ptr.count_nonzero()
            sh[0] = num_elem
            data = PyArray_SimpleNew(1, sh, {{num}})

            # now stack the indices: row[0], ..., row[n], col[0], ..., col[n], ...
            # (where `n` is the number of nonzero elements)
            nd = self.view.p.{{ct}}_ptr.ndim()
            sh[0] *= nd

            stacked_indices = PyArray_SimpleNew(1, sh, NPY_INTP)
            to_coo[{{ct}}, npy_intp](self.view.p.{{ct}}_ptr,
                             PyArray_DATA(data),
                             PyArray_DATA(stacked_indices),
                             num_elem)
            indices = tuple(stacked_indices[j*num_elem : (j+1)*num_elem] for j in range(nd))
            return data, indices
        {{endfor}}

    @classmethod
    def from_coo(cls, data, row_col):
        """Construct from a COO style triplet of arrays.

        Given three 1D arrays, `data`, `row` and `col`, return a MapArray
        instance ``m`` such that ``m[row[k], col[k]] = data[k]`` for
        ``k in range(n)``.

        Parameters
        ----------
        data : array_like, shape (n, )
            Nonzero values.
        (row, col) :  tuple of array_likes, both shape (n,)
            Indices of nonzero elements.

        """
        row, col = row_col
        self = MapArray(dtype=data.dtype, ndim=2)
        for val, r, c in zip(data, row, col):
            self[r, c] = val
        return self

    def _make_view(self, slices=None):
        m = MapArray(self.shape, self.ndim, self.fill_value, self.dtype)
        m.holder = self.holder
        if slices is None:
            m.view = View.from_data(self.typenum, self.holder)
        else:
            m.view = View.from_view(self.typenum, self.view, slices)
        m._base = self
        #m.own_data = False
        return m

    ##### Single element access #####

    def __getitem__(self, tpl):
        # no slicing, single-element access only
        if not isinstance(tpl, tuple):
            tpl = (tpl,)

        cdef npy_cdouble_wrapper z
        cdef index_type idx = self.index_factory.get_new()
        if _is_tuple_of_integers(tpl, idx, self.index_factory.ndim()):
            {{for NUM, CT in zip(TNUMS_GEN, CTYPES_GEN)}}
            if self.typenum == {{NUM}}:
                validate_index[{{CT}}, npy_intp](idx, self.view.p.{{CT}}_ptr, True)
                return self.view.p.{{CT}}_ptr.get_one(idx)

            {{endfor}}
            if self.typenum == NPY_BOOL:
                validate_index[npy_bool, npy_intp](idx, self.view.p.npy_bool_ptr, True)
                return self.view.p.npy_bool_ptr.get_one(idx) != 0

            if self.typenum == NPY_CDOUBLE:
                validate_index[npy_cdouble_wrapper, npy_intp](idx, self.view.p.npy_cdouble_wrapper_ptr, True)
                z = self.view.p.npy_cdouble_wrapper_ptr.get_one(idx)
                return PyComplex_FromDoubles(z.real, z.imag)
            raise TypeError("__getitem__: dtype = %s not understood." % self.dtype)

#        elif tpl is Ellipsis:
#            slices = tuple(slice(None,) for _ in range(self.ndim))
        else:
            slices = tuple_to_slices(tpl, self.shape)
            return self._make_view(slices)
        raise IndexError("%s cannot be interpreted as an index into "
                         " an array." % str(tpl))

    def __setitem__(self, tpl, value):
        if self.ndim == 1:
            tpl = (tpl,)
        cdef index_type idx = self.index_factory.get_new()
        if not _is_tuple_of_integers(tpl, idx, self.index_factory.ndim()):
            raise IndexError("%s cannot be interpreted as an index into "
                             " an array." % str(tpl))

        cdef int ival
        cdef npy_cdouble_wrapper z

        {{for num, ct, IF in zip(TNUMS_GEN, CTYPES_GEN, CONDS_GEN)}}
        {{IF}} self.typenum == {{num}}:
            validate_index[{{ct}}, npy_intp](idx, self.view.p.{{ct}}_ptr, self._is_shape_fixed)
            self.view.p.{{ct}}_ptr.set_one(idx, value)

        {{endfor}}
        elif self.typenum == NPY_BOOL:
            validate_index[npy_bool, npy_intp](idx, self.view.p.npy_bool_ptr, self._is_shape_fixed)
            ival = PyObject_IsTrue(value)
            if ival == -1:
                raise ValueError("Cannot interpet %s as a boolean" % value)
            self.view.p.npy_bool_ptr.set_one(idx, ival)

        elif self.typenum == NPY_CDOUBLE:
            validate_index[npy_cdouble_wrapper, npy_intp](idx,
                                                self.view.p.npy_cdouble_wrapper_ptr,
                                                self._is_shape_fixed)
            ival = PyComplex_Check(value)
            if ival == -1:
                raise ValueError("Cannot interpret %s as a complex number" % value)
            z.real = PyComplex_RealAsDouble(value)
            z.imag = PyComplex_ImagAsDouble(value)
            self.view.p.npy_cdouble_wrapper_ptr.set_one(idx, z)
        else:
            raise TypeError("__setitem__: dtype = %s not understood." % self.dtype)

    ###### Arithmetics #######

    # XXX maybe add more arithm ops: div, l/r shifts, mod etc

    {{for op, symb in zip(["add", "mul", "sub"], ["+", "*", "-"])}}
    def __i{{op}}__(MapArray self not None, other):
        if isinstance(other, np.ndarray): 
            # hand over to __{{op}}__ for densification
            return NotImplemented

        if isinstance(other, MapArray):
            return _i{{op}}_impl(self, other)

        # try checking if other quacks like a scipy.sparse matrix
        if hasattr(other, 'tocoo'):
            coo_other = _try_converting_from_sparse(other)
            if coo_other is NotImplemented:
                return coo_other
            return _i{{op}}_impl(self, coo_other)

        # else, other must be a scalar
        try:
            dt = np.asarray(other).dtype     # XXX there must be a more direct way
            arr_other = MapArray(shape=self.shape,
                                 dtype=dt,
                                 fill_value=other)
            return _i{{op}}_impl(self, arr_other)
        except TypeError:
            # failed to convert other to MapArray. Give up.
            return NotImplemented

    def __{{op}}__(self, other):
        if isinstance(self, MapArray):
            if isinstance(other, np.ndarray):
                # Densify and return dense result
                return self.todense() {{symb}} other
            else:
                newobj = self.copy()
                return newobj.__i{{op}}__(other)
        else:
            # other must be a MapArray
            if isinstance(self, np.ndarray):
                return self {{symb}} other.todense()

            # try checking if self quacks like a scipy.sparse matrix
            if hasattr(self, 'tocoo'):
                # csr*map is ambiguous: is it matrix multiply or elementwise?
                # refuse the temptation to guess and give up.
                # FIXME: this actually fails to work. The reason is that
                # sparse matrices check dimensions *before* handing over to
                # MapArray. Maybe the right thing to do is to bail out
                # from both csr * map and map * csr (even though the latter works).
                {{if op == "mul"}}
                raise ValueError("matrix times array is ambiguous. Please "
                                 "decide if you want matrix or elementwise "
                                 "multiplication.")
                {{else}}
                coo_self = _try_converting_from_sparse(self)
                if coo_self is NotImplemented:
                    return coo_self
                return _i{{op}}_impl(coo_self, other)
                {{endif}}

            # else, self must be a scalar
            try:
                dt = np.asarray(self).dtype     # XXX there must be a more direct way
                arr_self = MapArray(shape=other.shape,
                                    dtype=dt,
                                    fill_value=self)
                return _i{{op}}_impl(arr_self, other)
            except TypeError:
                # conversion to MapArray failed. Give up.
                return NotImplemented

    {{endfor}}

    ########### Booleans ########################

    def __richcmp__(self, other, int op):
        if not isinstance(self, MapArray):
            # __richcmp__ seems to sort out reversed ops ($1 < m$ -> $m >= 1$)
            # automagically
            raise ValueError("__richcmp__: %s %s %s" % (self, other, op))

        if isinstance(other, np.ndarray):
            return PyObject_RichCompare(self.todense(), other, op)

        if isinstance(other, MapArray):
            return _richcmp_impl(self, other, op)

        if hasattr(other, "tocoo"):
            coo_other = _try_converting_from_sparse(other)
            if coo_other is NotImplemented:
                return coo_other
            return _richcmp_impl(self, coo_other, op)            

        # else, other is a scalar
        dt = np.asarray(other).dtype     # XXX there must be a more direct way
        arr_other = MapArray(shape=self.shape,
                             dtype=dt,
                             fill_value=other)
        return _richcmp_impl(self, arr_other, op)

    def __matmul__(self, A):
        if isinstance(self, np.ndarray):
            return self.__matmul__(A.todense())
        if isinstance(A, np.ndarray):
            return self.todense().__matmul__(A)

        if not isinstance(self, MapArray) or not isinstance(A, MapArray):
            raise NotImplementedError("matmul only handles sparse arrays.")

        if self.ndim != 2 or A.ndim != 2:
            raise NotImplementedError("matmul is only implemented for 2D arrays.")

        if self.fill_value != 0 or A.fill_value != 0:
            raise NotImplementedError("The result is likely dense.")

        # figure out the result dtype and perform multiplication
        dtyp = np.promote_types(self.dtype, A.dtype)
        newobj = MapArray(dtype=dtyp)
        _mmul_impl(newobj, self, A)
        return newobj

    def __imatmul__(self, A):
        raise NotImplementedError("In-place matmul is not implemented. "
                                  "Use a = a @ b instead of a @= b.")

######## implementations

def _mmul_impl(MapArray self not None,
               MapArray A not None,
               MapArray B not None):
    # handle types
    if A.dtype != self.dtype:
        AA = A.astype(self.dtype)
        return _mmul_impl(self, AA, B)
    if B.dtype != self.dtype:
        BB = B.astype(self.dtype)
        return _mmul_impl(self, A, BB)

    # by now all arrays are of the same dtype
    {{for num, ct in zip(TNUMS, CTYPES)}}
    if self.typenum == {{num}}:
        apply_mmul[{{ct}}, npy_intp](self.view.p.{{ct}}_ptr,
                                     A.view.p.{{ct}}_ptr,
                                     B.view.p.{{ct}}_ptr)
        return self
    {{endfor}}
    raise NotImplementedError


def _richcmp_impl(MapArray self not None, MapArray other not None, int op):
    """ Sparse <op> sparse implementation of __richcmp__.

        Figure out the common dtype, copy if necessary. Then dispatch
        on the type.

        XXX: this can be made copy less (ditto for binops).
    """
    # figure out dtypes, copy if necessary         
    if self.typenum != other.typenum:
        res_type = np.promote_types(self.dtype, other.dtype)
        if res_type.num != self.typenum:
            # upcast self and operate on the copy
            newobj = self.astype(res_type)
            return _richcmp_impl(newobj, other, op)

        # by this stage, self.dtype == res_type
        if self.typenum != other.typenum:
            # upcast other
            other = other.astype(res_type)

    # by now, both self and other are of the same dtype
    result = MapArray(dtype=bool, ndim=self.ndim)

    # TODO: shove the switch on `op` into an enum, like PyObject_RichCompare does
    # dispatch on the types
    {{for num, ct in zip(TNUMS, CTYPES)}}
    if self.typenum == {{num}}:
        if op == 0:
            apply_binop[{{ct}}, npy_bool, npy_intp](less[{{ct}}],
                                          result.view.p.npy_bool_ptr,
                                          self.view.p.{{ct}}_ptr,
                                          other.view.p.{{ct}}_ptr)
        elif op == 1:
            apply_binop[{{ct}}, npy_bool, npy_intp](less_equal[{{ct}}],
                                          result.view.p.npy_bool_ptr,
                                          self.view.p.{{ct}}_ptr,
                                          other.view.p.{{ct}}_ptr)
        elif op == 2:
            apply_binop[{{ct}}, npy_bool, npy_intp](equal[{{ct}}],
                                          result.view.p.npy_bool_ptr,
                                          self.view.p.{{ct}}_ptr,
                                          other.view.p.{{ct}}_ptr)
        elif op == 3:
            apply_binop[{{ct}}, npy_bool, npy_intp](not_equal[{{ct}}],
                                          result.view.p.npy_bool_ptr,
                                          self.view.p.{{ct}}_ptr,
                                          other.view.p.{{ct}}_ptr)
        elif op == 4:
            apply_binop[{{ct}}, npy_bool, npy_intp](greater[{{ct}}],
                                          result.view.p.npy_bool_ptr,
                                          self.view.p.{{ct}}_ptr,
                                          other.view.p.{{ct}}_ptr)
        elif op == 5:
            apply_binop[{{ct}}, npy_bool, npy_intp](greater_equal[{{ct}}],
                                          result.view.p.npy_bool_ptr,
                                          self.view.p.{{ct}}_ptr,
                                          other.view.p.{{ct}}_ptr)
        else:
            raise ValueError("sparse cmp: op = ." % op)
        return result

    {{endfor}}


{{for op in ["add", "mul", "sub"]}}
def _i{{op}}_impl(MapArray self not None, MapArray other not None):
    """ Sparse <op> sparse implementation of __i{{op}}__.

        Figure out the common dtype, copy if necessary. Then dispatch
        on the type.
    """
    # figure out dtypes, copy if necessary
    if self.typenum != other.typenum:
        res_type = np.promote_types(self.dtype, other.dtype)
        if res_type.num != self.typenum:
            # upcast self and operate on the copy
            newobj = self.astype(res_type)
            return _i{{op}}_impl(newobj, other)

        # by this stage, self.dtype == res_type
        if self.typenum != other.typenum:
            # upcast other
            other = other.astype(res_type)

    # dispatch
    {{for num, ct in zip(TNUMS, CTYPES)}}
    if self.typenum == {{num}}:
        inplace_binop[{{ct}}, npy_intp]({{op}}[{{ct}}],
                                        self.view.p.{{ct}}_ptr,
                                        other.view.p.{{ct}}_ptr)
        return self
    {{endfor}}
    raise NotImplementedError("_i{{op}}_: typecode %s not understood." % self.typenum)
{{endfor}}


def _try_converting_from_sparse(what):
    """Convert a scipy.sparse matrix to MapArray. To be used in binops.
    """
    coo = what.tocoo()
    try:
        data, row, col = coo.data, coo.row, coo.col
    except AttributeError:
        return NotImplemented
    row = row.astype(np.intp)  # XXX how MapArray.from_coo wants it
    col = col.astype(np.intp)
    return MapArray.from_coo(data, (row, col))


def tuple_to_slices(tpl, shape):
    """Convert a tuple of slices/integers into a tuple of slices."""

    # FIXME: unless there are Noness
    if len(tpl) > len(shape):
        raise IndexError("tpl too long.")

    ell_pos = -1
    res = []
    for j, x in enumerate(tpl):
        if isinstance(x, slice):
            res.append(x)
        elif isinstance(x, int):
            # TODO: check if in bounds (numpy does)
            if (x >= shape[j]) or (x < -shape[j]):
                raise IndexError("Index %s is out of bounds for the axis %s "
                                 "with size %s." % (x, j, shape[j]))
            res.append(slice(x, x+1))
        elif x is Ellipsis:
            if ell_pos != -1:
                raise IndexError("Only one Ellipsis is allowed.")
            ell_pos = j
        elif x is None:
            raise IndexError("newaxis is not supported yet.")
        else:
            raise IndexError("Entry %s not understood." % x)

    # Ellipsis
    if ell_pos != -1:
        num = len(shape) - len(res)
        res = res[:ell_pos] + [slice(None) for _ in range(num)] + res[ell_pos:]

    numt = len(shape) - len(res)
    if numt > 0:
        raise IndexError("no changing of dims yet.")
        # fill the remaining trailing dims with slice(None)-s
        res += [slice(None) for _ in range(numt)]

    return tuple(res)


cnp.import_array()
